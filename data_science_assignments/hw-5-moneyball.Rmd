---
title: "Homework 5"
name: "Hillary Miller"
output: html_document
---

```{r, message=FALSE, warning=FALSE}
library(Lahman)
library(tidyverse)
library(broom)
```

# Problem 1 - Money Ball

_Moneyball: The Art of Winning an Unfair Game_ is a book by Michael Lewis about the Oakland Athletics baseball team in 2002 and its general manager, the person tasked with building the team, Billy Beane. During Billy Bean's tenure as general manager, ownership cut the budget drastically leaving the general manager with one of the lowest payrolls in baseball. Money Ball tells the story of how Billy Bean used analysts to find inefficiencies in the market. Specifically, his team used data science to find low cost players that the data predicted would help the team win.

Statistics have been used in baseball since its beginnings. Note that `Lahman` (a library containing an extensive baseball database) goes back to the 19th century. Batting average, for example, has been used to summarize a batter's success for decades. [Other statistics](http://mlb.mlb.com/stats/league_leaders.jsp) such as home runs (HR), runs batted in (RBI) and stolen bases have been reported and players rewarded for high numbers. However, until [Bill James](https://en.wikipedia.org/wiki/Bill_James) introduced [sabermetrics](https://en.wikipedia.org/wiki/Sabermetrics), careful analyses had not been done to determine if these statistics actually help a team win. To simplify the exercise we will focus on scoring runs and ignore pitching and fielding. 

## Problem 1A

Here, we will use the `Lahman` library. You can see tables that are available when you load this package by typing:

```{r, eval=FALSE}
?Lahman
View(Teams)
```

Use the data in the `Teams` table to explore the relationship between stolen bases (SB) and runs per game in 1999. Make a plot, fit a regression line, and report the coefficients. If you take the coefficient at face value, how many more runs per game does a team score for every extra SB per game?

**The coefficient of the fitted regression line is 0.4294013, so if you take the coefficient at face value, a team scores .429 more runs per game for every extra stolen base per game. (So 10 extra stolen bases would result, on average, in 4.3 more runs per game.)**

```{r}
library(dplyr)
library(ggplot2)
## yearID = year
##SB = stolen bases
##R = runs scored
##G = games played
dat <- Teams %>% filter(yearID == 1999 ) %>%
  mutate(SB_per_game = SB/G, R_per_game = R/G)

mod.1 <- lm(R_per_game ~ SB_per_game, data = dat) 

p <- Teams %>% filter(yearID == 1999 ) %>%
  mutate(SB_per_game = SB/G, R_per_game = R/G) %>%
  ggplot(aes(SB_per_game, R_per_game)) + 
  geom_point(alpha = 0.5)
 
p + geom_smooth(method = "lm") ##which will give us a  line that is equivalent to the mod.1 fitted line

mod.1$coefficients[2]
```

## Problem 1B

In Problem 1A we observed a positive relationship between scoring runs and stealing bases. However, the estimated slope coefficient is a random variable. There is chance involved in scoring a run. So how do we know if this observed relationship was not just chance variability?

To examine the variability of this random variable we will consider each year to be a new independent outcome. Use the `lm` and `do` functions to fit a linear model to each year since 1961 (when they started playing 162 games per year). Hint: use the function `tidy` in `broom` to process the regression in each group so that it can be recombined (see [here](https://cran.r-project.org/web/packages/broom/vignettes/broom_and_dplyr.html) for examples).

Using this approach, what is your estimate of the slope random variable's standard error? Is the distribution of the random variable well approximated by a normal distribution? If so, use this to provide a 95% confidence interval for our effect of stolen bases on runs per game. Do you think stolen bases help score runs?

**Based on the outputs and plots of the residuals of the linear  regression (below), I would conclude the distribution is approximated by a normal (although n is quite small here, and some deviation from normality can be seen on the QQ-plot and the Histogram). The estimate of the slope random variable's standard error is 0.4098, with a 95% Confidence Interval of [-0.756,0.850]. Given that 0 is included in the confidence interval, I conclude that there is not sufficient statistical evidence that stolen bases help score runs.**



```{r}
#creating the regression line, stratified by year
dat <- Teams %>% filter(yearID %in% 1961:2001 ) %>% mutate(SB_per_game = SB/G, R_per_game = R/G) 
dat %>% group_by(yearID) %>%
  do(fit = lm(R_per_game ~ SB_per_game, data = .))


mod.2 <- dat %>%  
  group_by(yearID) %>%
  do(tidy(lm(R_per_game ~ SB_per_game, data = .), conf.int = TRUE)) %>%
  filter(term == "SB_per_game") %>%
  select(yearID, estimate, conf.low, conf.high)

##checking for normality
qqnorm(mod.2$estimate)
qqline(mod.2$estimate)
hist(mod.2$estimate)

##to find the standard deivation
sd(mod.2$estimate)
##The 95% confidence interval
mean(mod.2$estimate)-1.96*sd(mod.2$estimate)
mean(mod.2$estimate)+1.96*sd(mod.2$estimate)

```


```{r}
##to visualize the CI by yearID grouping:
dat %>%  
  group_by(yearID) %>%
  do(tidy(lm(R_per_game ~ SB_per_game, data = .), conf.int = TRUE)) %>%
  filter(term == "SB_per_game") %>%
  select(yearID, estimate, conf.low, conf.high) %>%
  ggplot(aes(yearID, y = estimate, ymin = conf.low, ymax = conf.high)) +
  geom_errorbar() +
  geom_point()
```


## Problem 1C

Even if we didn't have several years to examine the distribution of our estimate, there is a version of the CLT that applies to regression. It turns out that with a large enough sample size, in this case the number of teams, we can construct a confidence interval. Use the function `tidy` to report a confidence interval for the effect of SB on runs based exclusively on the 1999 data. What are your thoughts now on the effectiveness of recruiting players that can steal bases?

**Using the tidy function and the linear model created in 1a, we can see that the confidence interval is [-.453,1.312] for the effect of stolen bases on number of runs per game. Again, this value includes zero, and we cannot conclude that stealing bases results in runs. Due to this, it does not appear to be effective to recruit players based on their probability to steal bases. (I also calculated CIs by the manual function below, using the standard error outputs from the model, and got [-0.415,1.274] and while the numbers are slightly different due to r's internal rounding, the conclusion is the same.)**


```{r}
##recreating the model from 1a
dat <- Teams %>% filter(yearID == 1999 ) %>%
  mutate(SB_per_game = SB/G, R_per_game = R/G)

mod.1 <- lm(R_per_game ~ SB_per_game, data = dat) 

conf <- tidy(mod.1, conf.int = TRUE) 
conf %>% filter(term == "SB_per_game")

##can also calculate by finding summary of the model and calculating the CI by  hand:
summary(mod.1)

#CI
coef(mod.1)[2]-(qnorm(.975)*(coef(summary(mod.1))[2,2]))
coef(mod.1)[2]-(qnorm(.025)*(coef(summary(mod.1))[2,2]))
```

## Problem 1D

Back in 2002 (the year of the [money ball](https://en.wikipedia.org/wiki/Moneyball) story described above), bases on balls (BB) did not receive as much attention as other statistics. Repeat the above analysis we performed in 1C for BB per game in 1999. Do BB have a larger effect on runs than SB?

**Yes, using the tidy function and a linear model with BB/game, we can see that the confidence interval is [0.266,0.827] for the effect of walks by batters on number of runs per game. Looking at the model summary alone, we can see that the estimate effect of BB on runs is .547, which is higher than the estimate of stolen bases per game, .429, found above. Since the confidence interval does not include zero, we can conclude that an increase in BB is associated with an increase in runs per game. (I also calculated CIs by the manual function below, using the standard error outputs from the model, and got [0.278,0.815] and while the numbers are slightly different due to r's internal rounding, the conclusion is the same.)**


```{r}
##BB = Walks by batters
dat <- Teams %>% filter(yearID == 1999 ) %>%
  mutate(BB_per_game = BB/G, R_per_game = R/G)

mod.1d <- lm(R_per_game ~ BB_per_game, data = dat) 

conf <- tidy(mod.1d, conf.int = TRUE) 
conf %>% filter(term == "BB_per_game")

##can also calculate by finding summary of the model and calculating the CI by  hand:
summary(mod.1d)

#CI
coef(mod.1d)[2]-(qnorm(.975)*(coef(summary(mod.1d))[2,2]))
coef(mod.1d)[2]+(qnorm(.025)*(coef(summary(mod.1d))[2,2]))
```

## Problem 1E

Association is not causation. It turns out that HR hitters also obtain many BB. We know for a fact that HRs cause runs because, by definition, they produce at least one. We can see this by simply plotting these two statistics for all players with more than 500 plate appearances (`BB+AB`):

```{r}
Batting %>%
  filter(yearID >= 1961 & BB+AB > 500 & !is.na(HR) & !is.na(BB)) %>% 
  mutate(HR = factor(pmin(HR, 40))) %>%
  ggplot(aes(HR, BB)) +
  geom_boxplot()
```

So, is the relationship we saw above for BB and runs due to teams having more HRs also having more BBs? One way we can explore this is by keeping HR fixed and examining the relationship within the strata. For example, if we look only at teams with 150 HRs, do more BBs produce more runs?

We can't perform this analysis on a single year, because there are not enough teams to obtain strata with more than one or two teams. Instead we will combine all data across years since 1961. 

Group data by the number of HRs and perform a regression analysis in each stratum to determine the effect of BB per game on runs per game. Use 10th, 20th, ... quantiles to split the data into 10 groups. Hint: use the function `cut` and `quantile` to create the strata. Does the relationship between BB and runs seem linear within each strata?

**Yes, based on the coefficients of the fitted models and the linear plots of each group, the relationship between BB and runs does seem linear within each homerun strata. Also, looking at the p-values and 95% CIs for each strata, increased BBs per game does seem to be associated with increased number of runs within each strata, but the magnitude of the effect of BB on runs does not change much between in strata.**

```{r}
##HR = home runs
#creating the groups
dat.1e <- Teams %>%
  filter(yearID >= 1961) %>% 
  mutate(BB_per_game = BB/G, R_per_game = R/G, HR_per_game = HR/G) %>% 
  mutate(group = cut(HR_per_game, quantile(HR_per_game, prob = seq(0, 1, .1)), include.lowest = TRUE))

#fitting the linear model
mod.1e <- dat.1e %>%  
  group_by(group) %>%
  do(tidy(lm(R_per_game ~ BB_per_game, data = .), conf.int = TRUE)) %>%
  filter(term == "BB_per_game")
mod.1e

##It appears linear, but should view to be sure

dat.1e %>% ggplot(aes(BB_per_game, R_per_game)) +  geom_point() + geom_smooth(method = "lm") + 
  facet_wrap(~group)

```

## Problem 1F

In problem 1E, we saw that the effect of BB on runs appears to be about the same in each strata. The relationship between HR and R is also, not surprisingly, linear:

```{r}
Teams %>%
  filter(yearID >= 1961) %>% 
  mutate(R = R / G, HR = HR / G) %>%
  ggplot(aes(HR, R)) +
  geom_point()
```

These two combined implies that a sensible linear model says:

$$
\mbox{Runs} = \beta_0 + \beta_{BB} \mbox{BB} + \beta_{HR}{HR} + \varepsilon
$$

In this model, we _adjust_ for HRs by including it as linear term. Note that we have already shown data that support this model. In general, simply fitting such a model does not necessarily adjust for a possible confounder. The model must also be approximately correct.

We can fit this model like this:

```{r}
fit <- Teams %>%
  filter(yearID >= 1961) %>% 
  mutate(R = R / G, BB = BB / G, HR = HR / G) %>%
  lm(R ~ BB + HR, data = .)
summary(fit)
```

Note that the summary shows a very strong HR effect but also a decent BB effect. Now, what happens if we include singles (`H-X2B-X3B-HR`), extra bases (doubles plus triples, `X2B + X3B`), and HRs per game in our model? What does the model say about which of these characteristics should receive more weight? 

**Based on the summary output of the model, looking at the coefficients alone, it appears HR per game still carries the most weight of all other variables. All have a statistically significant p-value (p<<.001), but based on magnitude of coefficient estimate: HR per game (1.398) should be weight the most, then extra bases per game (0.770), singles per game (0.555) and finally walks per game (0.364). Diving deeper, we can see that the 95% confidence intervals do not overlap.**

Also, fit the model to each year independently to check for consistency from year to year. Does the model appear consistent over time?

**Looking year to year (plot below) this general trend appears to hold from year to year. Per year, HRs per game always results in the highest association (based on the linear regression model), yet one or two years seem to have some deviation from the ranking of extra bases, singles, and walks. Yet, overall, this model is consistent.**

```{r}
##H = Hits by batters
## X2B =Doubles
##X3B = Triples
##for singles: H-X2B-X3B-HR
##for doubles plus triples: X2B+X3B
dat.1f <- Teams %>%
  filter(yearID >= 1961) %>% 
  mutate(singles = (H-X2B-X3B-HR)/G, extra_bases = (X2B+X3B)/G, R_per_game = R / G, BB_per_game = BB / G, HR_per_game = HR / G)

mod.1f <- lm(R_per_game ~ HR_per_game + BB_per_game + singles + extra_bases, data = dat.1f)
summary(mod.1f)

 
confidence_int <- dat.1f %>% do(tidy(lm(R_per_game ~ HR_per_game + BB_per_game + singles + extra_bases, data = .), conf.int = TRUE))
confidence_int
```

```{r}
mod.1f2 <- Teams %>%
  filter(yearID >= 1961) %>% group_by(yearID) %>% mutate(singles = (H-X2B-X3B-HR)/G, extra_bases = (X2B+X3B)/G, R_per_game = R / G, BB_per_game = BB / G, HR_per_game = HR / G) %>%  do(tidy(lm(R_per_game ~ HR_per_game + BB_per_game + singles + extra_bases, data = .))) %>% filter(term != "(Intercept)") %>%
  ggplot(aes(yearID, estimate, group = term, col = term)) +
  geom_line() + scale_x_continuous(breaks=seq(1960,2017,5)) +
  geom_point() + ylab("Estimate of a Term for all teams in a given year") + xlab("Year")

mod.1f2
```


# Problem 2 - Reporting Heights Correctly?

Load the `heights` data from the dslabs package:

```{r}
library(dslabs)
data("heights")
```

Note that there are some very low heights reported. Here are the three shortest females:

```{r}
heights %>% 
  filter(sex == "Female") %>% 
  arrange(height) %>% 
  slice(1:3)
```

To quantify how below average these heights are, let's assume female heights follow a normal distribution and compute the probability of picking a female that is 55 inches or shorter. 

## Problem 2A

Start by computing the average and the standard deviation for female heights.

**The average female heigh is ~64.94 inches, with a standard deviation of ~3.76 inches.**

```{r}
heights %>% 
  filter(sex == "Female") %>% summarize(avg = mean(height), sd = sd(height))
```

## Problem 2B

If we approximate the female heights with a normal distribution with the average and standard deviation you just computed, what is the probability of picking a person at random and seeing someone 55 inches or shorter?

**Based on the normal approximation, there is a .004 probability or .4% chance of getting someone in our with a height of 55 inches.**

```{r}
pnorm(55, mean = 64.93942, sd = 3.760656)
```


## Problem 2C

The probability is quite low. Is it possible that the three shortest people meant to enter 5'5 (65 inches) and forgot to enter the `'`? 

We will use a Bayesian analysis to answer this. Suppose we pick a female at random. Let the random variable representing the actual height be $X$ and the reported height $Y$. Let $Z$ be a random variable for whether the person entered their height incorrectly and forgot the `'`. $Z=1$ if they made a mistake. 

So if the reported height is $Y=55$ and $Z=1$ the actual height is $X=5*12+5=65$, and if $Z=0$ then the actual and reported height are the same $X=Y=55$. 

Assume that the probability of making this error is $\mbox{Pr}(Z=1)$ = $\pi$. Use Bayes' formula to compute the probability they made a mistake given that $55$ is reported. Express the following probability as a function of $\pi$, then compute it for $\pi = 0.01$.

$$\mbox{Pr}(Z = 1 \mid Y=55)$$


$$
\mbox{Pr}(Z = 1 \mid Y=55) =
\frac{ \mbox{Pr}( Y =55 | Z =1 ) \pi}
{\mbox{Pr}(Y=55|Z=1) \pi + \mbox{Pr}(Y=55|Z=0) (1-\pi)}
$$
Now if $f_X$ is the normal density, for the actual density this is equal to:

$$
\mbox{Pr}(Z = 1 \mid Y=55) =
\frac{ f_X(65) \pi}
{f_X(65) \pi + f_X(55) (1-\pi)}
$$

We can compute the probability that an error was made given a reported height of 55 (assuming heights in our dataset are approximately normal) as:

```{r}
p_55 = pnorm(55, mean = 64.93942, sd = 3.760656)
p_65 = pnorm(65, mean = 64.93942, sd = 3.760656)

(p_65*.01)/((p_65*.01)+(p_55*(1-.01)))

```

**The probability that an error was made, given the probability of making an error, pi = .01, is .55 or 55%.**

## Problem 2D

Now, what if we look at different $\pi$ values? Generate a plot for $\mbox{Pr}(Z = 1 \mid Y=55)$ for `\pi` from 0.001 to 0.10. What do you observe?

```{r}

data.frame(pi= seq(.001,.10, by=.001)) %>% mutate(probability_error =  (p_65*pi)/((p_65*pi)+(p_55*(1-pi)))) %>% ggplot() + geom_point(aes(x=pi, y=probability_error), col="red") + xlab("Probability that the height entered was not correct (pi)") + ylab("Probability that an entry error was made (forgetting the ')") + ggtitle("Prob an entry error was made in data, for differing levels of pi, for height=55") + scale_y_continuous(breaks=seq(0,1,.1))

```

**The conditional probability that an entry error was made by entering a height of 55 inches increases as the probaility of entering an error (pi) increases. On the graph, you can see that the probability of an error is about 55% when pi=.01, as we calculated above. Yet the conditional probabilty increases less rapidly after pi=.025, and levels off.**


## Problem 2E

What if we look at different heights ($y$)? Generate a plot for $\mbox{Pr}(Z = 1 \mid Y = y)$ for $y=50,\dots,59$ when $\pi$ = 0.01. What do you think about this pattern? Note: recalling from 2C that: 

$$
\mbox{Pr}(Z = 1 \mid Y=y) =
\frac{ f_X(y+10) \pi}
{f_X(y+10) \pi + f_X(y) (1-\pi)}
$$

```{r}
data.frame(heights= seq(50,59, by=.1)) %>% mutate(probability_error =  (pnorm(heights+10, mean = 64.93942, sd = 3.760656)*.01)/((pnorm(heights+10, mean = 64.93942, sd = 3.760656)*.01)+(pnorm(heights, mean = 64.93942, sd = 3.760656)*(1-.01)))) %>% ggplot() + geom_point(aes(x=heights, y=probability_error), col="purple") + scale_y_continuous(breaks=seq(0,1,.1)) + xlab("Height values entered (getting closer to the mean)") + ylab("Probability that an entry error was made, for fixed pi=.01") + ggtitle("Prob an entry error was made in data, for differing heights entered")
```

**For a fixed level of pi, the probability that an entry error was made decreases in a sigmoidal pattern as the height values get closer to the average (which is roughly 65 inches for our data set). Note that a value of 50 entered for inches has about a 95% probability of an error, yet a height of 57.5 inches has about a 25% chance that is was entered incorrectly. A further exploration for heights above the average was conducted below, yet the formula had to be slightly altered to incorporate y-10. Yet the pattern again holds, and the probabilty of an error increases as the number moves away from the mean.**

```{r}
data.frame(heights= seq(75,85, by=.1)) %>% mutate(probability_error =  (pnorm(heights-10, mean = 64.93942, sd = 3.760656)*.01)/((pnorm(heights-10, mean = 64.93942, sd = 3.760656)*.01)+(pnorm(heights, mean = 64.93942, sd = 3.760656)*(1-.01)))) %>% ggplot() + geom_point(aes(x=heights, y=probability_error), col="purple") + xlab("Height values entered (getting further from the mean)") + ylab("Probability that an entry error was made, for fixed pi=.01") + ggtitle("Prob an entry error was made in data, for differing heights entered")
```
